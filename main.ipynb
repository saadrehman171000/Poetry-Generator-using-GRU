{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shaiiikh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2842/2842 - 23s - 8ms/step - accuracy: 0.0436 - loss: 6.9751\n",
            "Epoch 2/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.0623 - loss: 6.4712\n",
            "Epoch 3/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.0948 - loss: 6.1006\n",
            "Epoch 4/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.1187 - loss: 5.7179\n",
            "Epoch 5/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.1414 - loss: 5.3380\n",
            "Epoch 6/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.1640 - loss: 4.9707\n",
            "Epoch 7/30\n",
            "2842/2842 - 21s - 7ms/step - accuracy: 0.1959 - loss: 4.6172\n",
            "Epoch 8/30\n",
            "2842/2842 - 21s - 7ms/step - accuracy: 0.2330 - loss: 4.2805\n",
            "Epoch 9/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.2779 - loss: 3.9607\n",
            "Epoch 10/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.3232 - loss: 3.6605\n",
            "Epoch 11/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.3655 - loss: 3.3806\n",
            "Epoch 12/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.4056 - loss: 3.1263\n",
            "Epoch 13/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.4455 - loss: 2.8984\n",
            "Epoch 14/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.4796 - loss: 2.6939\n",
            "Epoch 15/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.5083 - loss: 2.5118\n",
            "Epoch 16/30\n",
            "2842/2842 - 23s - 8ms/step - accuracy: 0.5386 - loss: 2.3474\n",
            "Epoch 17/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.5631 - loss: 2.2029\n",
            "Epoch 18/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.5880 - loss: 2.0721\n",
            "Epoch 19/30\n",
            "2842/2842 - 23s - 8ms/step - accuracy: 0.6085 - loss: 1.9545\n",
            "Epoch 20/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.6287 - loss: 1.8489\n",
            "Epoch 21/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.6458 - loss: 1.7509\n",
            "Epoch 22/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.6620 - loss: 1.6665\n",
            "Epoch 23/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.6778 - loss: 1.5863\n",
            "Epoch 24/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.6892 - loss: 1.5167\n",
            "Epoch 25/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.7035 - loss: 1.4478\n",
            "Epoch 26/30\n",
            "2842/2842 - 22s - 8ms/step - accuracy: 0.7136 - loss: 1.3875\n",
            "Epoch 27/30\n",
            "2842/2842 - 23s - 8ms/step - accuracy: 0.7235 - loss: 1.3348\n",
            "Epoch 28/30\n",
            "2842/2842 - 23s - 8ms/step - accuracy: 0.7348 - loss: 1.2821\n",
            "Epoch 29/30\n",
            "2842/2842 - 26s - 9ms/step - accuracy: 0.7417 - loss: 1.2362\n",
            "Epoch 30/30\n",
            "2842/2842 - 23s - 8ms/step - accuracy: 0.7497 - loss: 1.1930\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "2025-02-08 22:17:14.289 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.463 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run c:\\Users\\shaiiikh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
            "2025-02-08 22:17:14.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.464 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.465 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.465 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.466 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.467 Session state does not function when running a script without `streamlit run`\n",
            "2025-02-08 22:17:14.467 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.468 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.468 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.468 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-02-08 22:17:14.469 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import streamlit as st  # For creating web interface\n",
        "import numpy as np  # For numerical operations\n",
        "import pandas as pd  # For data manipulation\n",
        "import tensorflow as tf  # Deep learning framework\n",
        "from tensorflow.keras.models import Sequential  # For creating sequential neural network\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense  # Neural network layers\n",
        "from tensorflow.keras.optimizers import Adam  # Optimizer for training\n",
        "from keras.preprocessing.sequence import pad_sequences  # For padding input sequences\n",
        "from sklearn.preprocessing import LabelEncoder  # For encoding words to numbers\n",
        "import pickle  # For saving and loading Python objects\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "# Reading only first 700 entries from the CSV file to reduce computation\n",
        "poetry_data = pd.read_csv(\"roman urdu poetry.csv\").iloc[:700]\n",
        "poetry_lines = poetry_data[\"Poetry\"].dropna().tolist()  # Remove any null values and convert to list\n",
        "\n",
        "# Combine all poetry lines into a single text and split into words\n",
        "combined_text = \" \".join(poetry_lines)  # Join all poetry lines with space\n",
        "all_words = combined_text.split()  # Split text into individual words\n",
        "\n",
        "# Convert words to numerical format\n",
        "encoder = LabelEncoder()  # Initialize label encoder\n",
        "encoder.fit(all_words)  # Fit encoder on all unique words\n",
        "\n",
        "# Create mapping dictionaries for words to indices and vice versa\n",
        "word_to_idx = {word: idx for idx, word in enumerate(encoder.classes_)}  # Word to index mapping\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}  # Index to word mapping\n",
        "\n",
        "# Create training sequences\n",
        "# Each sequence contains 6 words (5 input words and 1 target word)\n",
        "sequence_data = []\n",
        "for i in range(len(all_words) - 5):\n",
        "    sequence_data.append([word_to_idx[word] for word in all_words[i: i + 6]])\n",
        "\n",
        "# Convert to numpy array and split into input (X) and target (y)\n",
        "sequence_data = np.array(sequence_data)\n",
        "X, y = sequence_data[:, :-1], sequence_data[:, -1]  # X: first 5 words, y: last word\n",
        "\n",
        "# Define the neural network architecture\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(word_to_idx), output_dim=50, input_length=X.shape[1]),  # Word embedding layer\n",
        "    GRU(100, return_sequences=False),  # GRU layer for sequence processing\n",
        "    Dense(len(word_to_idx), activation='softmax')  # Output layer for word prediction\n",
        "])\n",
        "\n",
        "# Configure model training parameters\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=30, verbose=2)  # Train for 30 epochs\n",
        "\n",
        "# Save the trained model and word encoder\n",
        "model.save(\"poetry_gru_model.h5\")  # Save neural network model\n",
        "with open(\"word_encoder.pkl\", \"wb\") as f:  # Save word encoder\n",
        "    pickle.dump(encoder, f)\n",
        "\n",
        "# Create Streamlit web interface\n",
        "st.title(\"Roman Urdu Nazam Generator\")\n",
        "user_input = st.text_input(\"Start your Nazam:\")  # Get initial words from user\n",
        "\n",
        "# Generate poetry when user clicks the button\n",
        "if st.button(\"Generate\"):\n",
        "    input_words = user_input.split()  # Split input into words\n",
        "    for _ in range(20):  # Generate 20 additional words\n",
        "        input_seq = [word_to_idx.get(word, 0) for word in input_words[-5:]]  # Get last 5 words\n",
        "        input_seq_padded = pad_sequences([input_seq], maxlen=5)  # Pad sequence to fixed length\n",
        "        predicted_idx = np.argmax(model.predict(input_seq_padded), axis=-1)[0]  # Predict next word\n",
        "        next_word = idx_to_word[predicted_idx]  # Convert predicted index to word\n",
        "        input_words.append(next_word)  # Add predicted word to sequence\n",
        "\n",
        "    st.write(\" \".join(input_words))  # Display generated poetry"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
